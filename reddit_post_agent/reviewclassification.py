# -*- coding: utf-8 -*-
"""ReviewClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MJl41w01t4WIrxh99CnHi2vydNEB-eU6
"""

import kagglehub
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sentence_transformers import SentenceTransformer, util



# Download latest version
path = kagglehub.dataset_download("lakshmi25npathi/imdb-dataset-of-50k-movie-reviews")

print("Path to dataset files:", path)

!pip install nltk
import nltk
nltk.download('punkt_tab')
nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('averaged_perceptron_tagger_eng')

ls $path

data = pd.read_csv(f"{path}/IMDB Dataset.csv")

data.head(2)

data['sentiment'] = (data['sentiment'] == 'positive').astype(int)

X = data.drop(['sentiment'],axis = 1)
Y = data['sentiment']

from sklearn.model_selection import train_test_split
X_train , X_test , y_train , y_test = train_test_split(
    X ,
    Y ,
    test_size = 0.2 ,
    shuffle = True
)

import spacy
import string
from sentence_transformers import SentenceTransformer

# Load spaCy (fast)
nlp = spacy.load("en_core_web_sm", disable=["ner", "parser"])
punct_table = str.maketrans("", "", string.punctuation)

# Load embedding model
model = SentenceTransformer("all-MiniLM-L6-v2")
model.max_seq_length = 256

def preprocess_spacy(texts):
    cleaned = []
    for doc in nlp.pipe(texts, batch_size=64):
        tokens = [
            token.lemma_
            for token in doc
            if not token.is_punct and not token.is_space
        ]
        cleaned.append(" ".join(tokens))
    return cleaned

def encode_batch(texts):
    return model.encode(texts, normalize_embeddings=True, batch_size=128)

cleaned_reviews = preprocess_spacy(X_train['review'].tolist())

embeddings = encode_batch(cleaned_reviews)

X_train_embeddings = pd.DataFrame(embeddings)

cleaned_reviews = preprocess_spacy(X_test['review'].tolist())

embeddings = encode_batch(cleaned_reviews)

X_test_embeddings = pd.DataFrame(embeddings)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter = 1000)
trained_model = model.fit(embeddings,y_train)
result = model.predict(X_test_embeddings)

from sklearn.metrics import accuracy_score
score = accuracy_score(result , y_test)